{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Face Detection and Emotion Recognition\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hwikvGPYu2oW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries and Data"
      ],
      "metadata": {
        "id": "o8LpXPZAvO9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import struct\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "-W9A-r6RelgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### CNN models ###\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\n",
        "from keras.utils import np_utils\n",
        "from keras.regularizers import l2#, activity_l2\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras import models\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers import Input, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "KTDuC9um4upk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_x7KaF9hD6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d38225-d291-4614-87a2-107d27ec4ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfyAjWdGeFV5"
      },
      "outputs": [],
      "source": [
        "from numpy import expand_dims, asarray\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# define the expected input shape for the model\n",
        "input_w, input_h = 224,224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1r5RADHeFV8"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import zoom\n",
        "from skimage.feature import hog\n",
        "import dlib\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip training data from drive\n",
        "\n",
        "!unzip -q '/content/drive/MyDrive/FYP/val_set.zip' \n",
        "!unzip -q '/content/drive/MyDrive/FYP/trainset.zip' \n",
        "!unzip -q '/content/drive/MyDrive/FYP/train.zip'"
      ],
      "metadata": {
        "id": "FuyZmr3n2lhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YoloV3 Model"
      ],
      "metadata": {
        "id": "hjjBvMYEvjN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "    x = inp\n",
        "    count = 0\n",
        "    for conv in convs:\n",
        "        if count == (len(convs) - 2) and skip:\n",
        "            skip_connection = x\n",
        "        count += 1\n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
        "        x = Conv2D(conv['filter'],\n",
        "                   conv['kernel'],\n",
        "                   strides=conv['stride'],\n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
        "                   name='conv_' + str(conv['layer_idx']),\n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\n",
        "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "    return add([skip_connection, x]) if skip else x"
      ],
      "metadata": {
        "id": "fsoXKhgaewXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_yolov3_model():\n",
        "    input_image = Input(shape=(None, None, 3))\n",
        "    # Layer  0 => 4\n",
        "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "    # Layer  5 => 8\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "    # Layer  9 => 11\n",
        "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "    # Layer 12 => 15\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "    # Layer 16 => 36\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "    skip_36 = x\n",
        "    # Layer 37 => 40\n",
        "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "    # Layer 41 => 61\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "    skip_61 = x\n",
        "    # Layer 62 => 65\n",
        "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "    # Layer 66 => 74\n",
        "    for i in range(3):\n",
        "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "    # Layer 75 => 79\n",
        "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "    # Layer 80 => 82\n",
        "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "                              {'filter':  18, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "    # Layer 83 => 86\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "    # Layer 87 => 91\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "    # Layer 92 => 94\n",
        "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "                              {'filter': 18, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "    # Layer 95 => 98\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "    # Layer 99 => 106\n",
        "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "                               {'filter': 18, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
        "    return model"
      ],
      "metadata": {
        "id": "fbLkA8KeeyK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightReader:\n",
        "    def __init__(self, weight_file):\n",
        "        with open(weight_file, 'rb') as w_f:\n",
        "            major,  = struct.unpack('i', w_f.read(4))\n",
        "            minor,  = struct.unpack('i', w_f.read(4))\n",
        "            revision, = struct.unpack('i', w_f.read(4))\n",
        "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "                w_f.read(8)\n",
        "            else:\n",
        "                w_f.read(4)\n",
        "                transpose = (major > 1000) or (minor > 1000)\n",
        "            binary = w_f.read()\n",
        "        self.offset = 0\n",
        "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
        "        \n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "        return self.all_weights[self.offset-size:self.offset]\n",
        "    \n",
        "    def load_weights(self, model):\n",
        "        for i in range(106):\n",
        "            try:\n",
        "                conv_layer = model.get_layer('conv_' + str(i))\n",
        "                print(\"loading weights of convolution #\" + str(i))\n",
        "                if i not in [81, 93, 105]:\n",
        "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "                    beta  = self.read_bytes(size) # bias\n",
        "                    gamma = self.read_bytes(size) # scale\n",
        "                    mean  = self.read_bytes(size) # mean\n",
        "                    var   = self.read_bytes(size) # variance\n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
        "                if len(conv_layer.get_weights()) > 1:\n",
        "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel, bias])\n",
        "                else:\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel])\n",
        "            except ValueError:\n",
        "                print(\"no convolution #\" + str(i))\n",
        "    \n",
        "    def reset(self):\n",
        "        self.offset = 0"
      ],
      "metadata": {
        "id": "W-jDC0UehodZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_yolov3_model()"
      ],
      "metadata": {
        "id": "Uqv9iJLIe9GJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "a12984f2-3f40-4f13-b483-43668fb235b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d09ab728c1f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_yolov3_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-f91c3ab211c5>\u001b[0m in \u001b[0;36mmake_yolov3_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_yolov3_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Layer  0 => 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n\u001b[1;32m      5\u001b[0m                                   \u001b[0;34m{\u001b[0m\u001b[0;34m'filter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stride'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bnorm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'leaky'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'layer_idx'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight_reader = WeightReader('/content/drive/MyDrive/FYP/yolov3-wider_16000.weights')\n",
        "weight_reader.load_weights(model)"
      ],
      "metadata": {
        "id": "OaPEuHmAfFvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/FYP/model.h5')"
      ],
      "metadata": {
        "id": "95EoxxHQhxQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Face Localization and Bounding box Helper functions"
      ],
      "metadata": {
        "id": "ydhF5ayLvwiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/MyDrive/FYP/model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjHTM8mSh1J2",
        "outputId": "5c11c839-f6b4-4a0b-8af1-88437eea20f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ojFsbCbeFV9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "        \n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "        \n",
        "        return self.label\n",
        "    \n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "        \n",
        "        return self.score\n",
        "\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S904LGqreFV-"
      },
      "outputs": [],
      "source": [
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "    grid_h, grid_w = netout.shape[:2] # 0 and 1 is row and column 13*13\n",
        "    nb_box = 3 # 3 anchor boxes\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1)) #13*13*3 ,-1\n",
        "    nb_class = netout.shape[-1] - 5\n",
        "    boxes = []\n",
        "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "    \n",
        "    for i in range(grid_h*grid_w):\n",
        "        row = i / grid_w\n",
        "        col = i % grid_w\n",
        "        for b in range(nb_box):\n",
        "            # 4th element is objectness score\n",
        "            objectness = netout[int(row)][int(col)][b][4]\n",
        "            if(objectness.all() <= obj_thresh): continue\n",
        "            # first 4 elements are x, y, w, and h\n",
        "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "            x = (col + x) / grid_w # center position, unit: image width\n",
        "            y = (row + y) / grid_h # center position, unit: image height\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
        "            # last elements are class probabilities\n",
        "            classes = netout[int(row)][col][b][5:]\n",
        "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "            boxes.append(box)\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "    new_w, new_h = net_w, net_h\n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmJb1cByeFWA"
      },
      "outputs": [],
      "source": [
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3\n",
        "\n",
        "#intersection over union        \n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "    intersect = intersect_w * intersect_h\n",
        "    \n",
        "    \n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin  \n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    \n",
        "    #Union(A,B) = A + B - Inter(A,B)\n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    return float(intersect) / union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pIo8HHceFWB"
      },
      "outputs": [],
      "source": [
        "def do_nms(boxes, nms_thresh):    #boxes from correct_yolo_boxes and  decode_netout\n",
        "    if len(boxes) > 0:\n",
        "        nb_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOsLo6H5eFWC"
      },
      "outputs": [],
      "source": [
        "# load and prepare an image\n",
        "def load_image_pixels(filename, shape):\n",
        "    # load the image to get its shape\n",
        "    image = load_img(filename) #load_img() Keras function to load the image .\n",
        "    width, height = image.size\n",
        "    # load the image with the required size\n",
        "    image = load_img(filename, target_size=shape) # target_size argument to resize the image after loading\n",
        "    # convert to numpy array\n",
        "    image = img_to_array(image)\n",
        "    # scale pixel values to [0, 1]\n",
        "    image = image.astype('float32')\n",
        "    image /= 255.0  #rescale the pixel values from 0-255 to 0-1 32-bit floating point values.\n",
        "    # add a dimension so that we have one sample\n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dfIMsSBtugq"
      },
      "outputs": [],
      "source": [
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl60m-kKeFWD"
      },
      "outputs": [],
      "source": [
        "# get all of the results above a threshold\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
        "    # enumerate all boxes\n",
        "    for box in boxes:\n",
        "        # enumerate all possible labels\n",
        "        for i in range(len(labels)):\n",
        "            # check if the threshold for this label is high enough\n",
        "            if box.classes[i] > thresh:\n",
        "                v_boxes.append(box)\n",
        "                v_labels.append(labels[i])\n",
        "                v_scores.append(box.classes[i]*100)\n",
        "    \n",
        "    return v_boxes, v_labels, v_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gO19RlDreFWE"
      },
      "outputs": [],
      "source": [
        "# draw all results\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "    #load the image\n",
        "    img = cv2.imread(filename)\n",
        "    for i in range(len(v_boxes)):\n",
        "        # retrieving the coordinates from each bounding box\n",
        "        box = v_boxes[i]\n",
        "        # get coordinates\n",
        "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "        start_point = (x1, y1) \n",
        "        # Ending coordinate\n",
        "        # represents the bottom right corner of rectangle \n",
        "        end_point = (x2, y2) \n",
        "        # Red color in BGR \n",
        "        color = (0, 0, 255) \n",
        "        # Line thickness of 2 px \n",
        "        thickness = 2\n",
        "        # font \n",
        "        font = cv2.FONT_HERSHEY_PLAIN \n",
        "        # fontScale \n",
        "        fontScale = 1.5\n",
        "        #create the shape\n",
        "        img = cv2.rectangle(img, start_point, end_point, color, thickness) \n",
        "        # draw text and score in top left corner\n",
        "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "        img = cv2.putText(img, label, (x1,y1), font,  \n",
        "                   fontScale, color, thickness, cv2.LINE_AA)\n",
        "    # show the plot\n",
        "    output = \"outputs/\"+filename.rsplit(\"/\")[1].rsplit(\".\")[0]+'_yolov3.jpg'\n",
        "    #save the image\n",
        "    cv2.imwrite(output,img)\n",
        "    cv2.imshow(\"yolov3\",img)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyjg5NXPA-Bj"
      },
      "outputs": [],
      "source": [
        "def face_crop(filename, v_boxes, v_labels, v_scores):\n",
        "    img = cv2.imread(filename)\n",
        "    rows, cols = img.shape[0], img.shape[1]\n",
        "    shape_x=48.0\n",
        "    shape_y=48.0\n",
        "    faces=[]\n",
        "    for i in range(len(v_boxes)):\n",
        "        if (not v_boxes):\n",
        "            x1,y1 = 0,0\n",
        "            x2,y2 = 0,0\n",
        "        else:\n",
        "            box = v_boxes[i]\n",
        "            y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "            cropped_image = img[y1:y2, x1:x2]\n",
        "            if cropped_image.shape[0]==0 or cropped_image.shape[1]==0:\n",
        "              print(cropped_image.shape,v_boxes[i],filename)\n",
        "              continue\n",
        "            new_extracted_face = zoom(cropped_image, (shape_x / cropped_image.shape[0],shape_y / cropped_image.shape[1],1),order=3, mode='wrap')\n",
        "            #cast type float\n",
        "            new_extracted_face = new_extracted_face.astype(np.float32)\n",
        "            #scale\n",
        "            new_extracted_face /= float(new_extracted_face.max())\n",
        "            faces.append(new_extracted_face)\n",
        "    return faces\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test YoloV3"
      ],
      "metadata": {
        "id": "mcJ3EvDqwLdR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0UBZAvceFWG"
      },
      "outputs": [],
      "source": [
        "# define the anchors\n",
        "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]  \n",
        "\n",
        "# define the probability threshold for detected objects\n",
        "class_threshold = 0.6\n",
        "\n",
        "labels = [\"face\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(argument):\n",
        "    labels = {0:'Neutral', 1:'Happy', 2:'Sad', 3:'Surprise', 4:'Fear' , 5:'Disgust', 6:'Anger', 7:'Contempt'}\n",
        "    return(labels.get(argument, \"Invalid emotion\"))"
      ],
      "metadata": {
        "id": "uv2O_1mAkCbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aFvwND0eFWI"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "def find_face(photo_filename):\n",
        "  boxes = list()\n",
        "  image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
        "  yhat = model.predict(image)\n",
        "  for i in range(len(yhat)):\n",
        "      # decode the output of the network\n",
        "      boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
        "      \n",
        "  # correct the sizes of the bounding boxes for the shape of the image\n",
        "  correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
        "\n",
        "  # suppress non-maximal boxes\n",
        "  do_nms(boxes, 0.5)  #Discard all boxes with pc less or equal to 0.5\n",
        "\n",
        "  # get the details of the detected objects\n",
        "  v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "\n",
        "  faces = face_crop(photo_filename, v_boxes, v_labels, v_scores)\n",
        "  return faces"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction"
      ],
      "metadata": {
        "id": "n6FMlNwD3nl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape_x = 48\n",
        "shape_y = 48\n",
        "window_size = 24\n",
        "window_step = 6"
      ],
      "metadata": {
        "id": "O8c2FmwMnmy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_hog_windows(image):\n",
        "    hog_windows = []\n",
        "    for y in range(0, shape_x, window_step):\n",
        "        for x in range(0, shape_y, window_step):\n",
        "            window = image[y:y+window_size, x:x+window_size]\n",
        "            hog_windows.extend(hog(window, orientations=8, pixels_per_cell=(8, 8),\n",
        "                                            cells_per_block=(1, 1), visualize=False))\n",
        "    return hog_windows"
      ],
      "metadata": {
        "id": "gQdanE1YmY7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dataset and apply"
      ],
      "metadata": {
        "id": "zPO-WO9i4Axe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_w, input_h = 224, 224\n",
        "directory = '/content/val_set/images/'\n",
        "# dir2 = '/content/trainset/images/'\n",
        "annotations = '/content/val_set/annotations/'\n",
        "# annot2 = '/content/trainset/annotations/'\n",
        "suffix = '_exp.npy'\n",
        "imgs = []\n",
        "target= []\n",
        "val_imgs = []\n",
        "val_target = []\n",
        "val_hog_slide_images = []\n",
        "val_hog_slide_features = []\n",
        "hog_slide_images = []\n",
        "hog_slide_features = []\n",
        "\n",
        "direct = '/content/train/'\n",
        "for dir in os.listdir(direct):\n",
        "  for filename in os.listdir(direct+dir):\n",
        "    photo_filename = direct+dir+\"/\"+filename\n",
        "    exp = int(dir)\n",
        "    img = cv2.imread(photo_filename)\n",
        "    img = zoom(img, (48 / img.shape[0],48 / img.shape[1],1),order=3, mode='wrap')\n",
        "    face = asarray(img)\n",
        "    face_1 = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "    image1 = face_1.reshape((shape_x, shape_y,1))\n",
        "    features = sliding_hog_windows(image1)\n",
        "    f, hog_image = hog(image1, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualize=True)\n",
        "    hog_slide_features.append(features)\n",
        "    hog_slide_images.append(hog_image)\n",
        "    imgs.append(image1)\n",
        "    target.append(exp)\n",
        "for filename in os.listdir(directory):\n",
        "  photo_filename = directory+filename\n",
        "  name = filename.split('.')[0]\n",
        "  with open(annotations+name+suffix,'rb') as f:\n",
        "    exp = np.load(f)\n",
        "  img = cv2.imread(photo_filename)\n",
        "  img = zoom(img, (48 / img.shape[0],48 / img.shape[1],1),order=3, mode='wrap')\n",
        "  face = asarray(img)\n",
        "  face_1 = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "  image1 = face_1.reshape((shape_x, shape_y,1))\n",
        "  features = sliding_hog_windows(image1)\n",
        "  f, hog_image = hog(image1, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualize=True)\n",
        "  val_hog_slide_features.append(features)\n",
        "  val_hog_slide_images.append(hog_image)\n",
        "  val_imgs.append(image1)\n",
        "  val_target.append(exp)"
      ],
      "metadata": {
        "id": "j4ICgSQQ1zZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(imgs)\n",
        "X = np.vstack(X)\n",
        "y = np.array(target)\n",
        "X = np.reshape(X, (len(imgs),48,48,1))\n",
        "y = np.reshape(y, (y.shape[0],1))\n",
        "train_data = X.astype('float32')\n",
        "train_data /= 255\n",
        "train_labels_one_hot = to_categorical(y)"
      ],
      "metadata": {
        "id": "wrgiA3_yyvfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = np.array(val_imgs)\n",
        "X_val = np.vstack(X_val)\n",
        "y_val = np.array(val_target)\n",
        "X_val = np.reshape(X_val, (len(val_imgs),48,48,1))\n",
        "y_val = np.reshape(y_val, (y_val.shape[0],1))\n",
        "val_data = X_val.astype('float32')\n",
        "val_data /= 255\n",
        "val_labels_one_hot = to_categorical(y_val)"
      ],
      "metadata": {
        "id": "Csg9MPrnZvOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[10,5])\n",
        "\n",
        "# Display the first image in training data\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(X[50],(48,48)))\n",
        "plt.title(\"Ground Truth : {}\".format(get_label(int(y[50]))))\n",
        "\n",
        "# Display the first image in testing data\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(X[6732],(48,48)))\n",
        "plt.title(\"Ground Truth : {}\".format(get_label(int(y[6732]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "bnJs5hcEjIuH",
        "outputId": "c02dc22c-331e-4bf0-a027-9996d64407c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ground Truth : Fear')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAEtCAYAAADHtl7HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9e5hlWVnm+X773E+cuEdeKzMr615QVFFgAdoIchFFxQYdRMURVBx0bFv7kRlEn2d6aMeeRp1Wcdp2xEZFGxtpUVGaVmkEFShKCpAqirpXZuU1MjMyrifOfe81f0QURMT3rsyz8xJVWfX+niefzPxirbXXXmvttVec837fZyEECCGEEEKI4Ume7A4IIYQQQlxp6AAlhBBCCJETHaCEEEIIIXKiA5QQQgghRE50gBJCCCGEyIkOUEIIIYQQOdEBSmzCzA6aWTCz4pNw7cNm9s3bfV0hxNMX7WnicqED1JOAmX2fmd1lZqtmdnr93z9hZvZk9+1cmFlzw5/MzNob/v8DOdv6fTP7xcvV1w3X+aH1zfN7L/e1hHimoj3t8u9pZvZOM+tv6fPbL9f1xPnRAWqbMbO3AXg3gF8BsBvALgA/DuDFAMqROoVt6+A5CCE0nvgD4AiA79xge/8T5Z6M3/TOwZsBzAN405PVgafK/AlxOdCetq388cY+hxB++VI2/hS6zysCHaC2ETMbB/ALAH4ihPAnIYSVsMYXQwg/EELorpf7fTP7LTP7qJmtAni5mT3LzD5pZotmdp+Z/fMN7X7SzH50w/9/yMw+teH/wcx+3MweXq//m0/8ZmhmBTP7f8xszsweA/AdF3BfLzOzY2b2s2Y2C+D3tvZhQz+uN7O3AvgBAG9f/y3qLzcUu93M7jGzJTP7YzOr5u3PhutdDeCbALwVwLea2W7S57et/8Z80sx+eMPPp83sL81s2cw+Z2a/uGVMbzazj5nZvJk9aGZv2PAzN38Xeg9CPJXRnra9e9o5+vsjZna/mS2Y2V+v731P/OzdZnZ0fS/7vJm9ZMPP3mlmf2Jm/9nMlgH80KXu29MZHaC2l28AUAHw4SHKvhHAvwUwCuAuAH8J4G8A7ATwLwG838xuynHt1wB4AYDbALwBwLeu2/+X9Z89D8AdAF6fo82N7AYwBeBqrB1YooQQ3gPg/QB+ef23qO/c8OM3AHg1gGvW+/pDrA0zO7C+cR44x6XeBODuEMKHANyPtQ1ua5/HAVwF4C0AftPMJtd/9psAVtfLvHn9zxPXHgHwMQB/hLX5+D4A/9HMnr2h7Y3zt2nTFeJphPY0bOuexuq9FsDPA/huADsA/AOA/7KhyOcA3L5+L38E4L9uOcS9FsCfAJhYvwcxJDpAbS8zAOZCCIMnDGb2mfWHpm1mL91Q9sMhhE+HEDKsLf4GgHeFEHohhL8F8BEA35/j2u8KISyGEI4A+MR6m8Daw/3rIYSjIYR5AP/uAu8tA/B/hhC6IYT2BbYBAL8RQjix3pe/3NDPTYQQjoQQJtbvJ8absLZhYP3vrV/j9QH8QgihH0L4KIAmgJts7euF/2n9flohhK8AeN+Geq8BcDiE8HshhEEI4YsAPgTgezaU+er8hRA6w926EFcc2tPOz6Xc096wPrZP/NmLta9L/10I4f71efi/sfap19Xr7f7nEMLZ9b3q32PtwLvxoHpnCOHP1/eqi7nPZxw6QG0vZwHM2IbvmUMI/yyEMLH+s43zcXTDv/cCOLq+8TzB41j75GRYZjf8u4W1zeurbW9p90I4c4kOCrF+5sLMXoy13/g+sG76IwC3mtnGzevsxo1/w/V2AChi87hs/PfVAF60cSPD2qdbuyPlhXi6oj3t/FySPW2dD64fsp74cwJr+9G7N+xF8wAM62NpZv/b+td7S+s/H8fawfcJtFddIDpAbS93Auhi7SPT8xE2/PsEgP1mtnG+DgA4vv7vVQD1DT/b+CI/HycB7N/S7oUQtvx/U5826o8i5S81b8baJvJP6xqGuzbYz8cZAAMA+zbYNo7RUQB/t2Uja4QQ/tcNZS73/QnxVEB7Wrz8dnEUwI9t2Y9qIYTPrOud3o61T+Um1w+2S1jbG59Ae9UFogPUNhJCWATwb7Cml3m9mY2aWbL+qcjIOarehbXfXN5uZiUzexmA78TXPl35JwDfbWZ1M7sea3qeYfkggJ8ys33r+p935LytGF8CcIuZ3b7+ffs7t/z8FIBrL9G1NrF+vTdgTbdw+4Y//xLAG+08niYhhBTAnwJ45/qY3ozNX/99BMCNZvaD6/NRMrMXmNmzLsf9CPFURXvaJi7bnnYe/j8AP2dmtwBrwn4ze0JOMIq1XwbPACia2b8GMPYk9PFpiQ5Q28y62+nPYO23glPrf34bwM8C+EykTg9rm8u3AZgD8B8BvCmE8MB6kV8D0Ftv633IJwT8HQB/jbXN4QtYOzhcNCGEh7DmnfM/ADwML6R+L4Bnr3/s/Od5218XXDYjgsvXAWgD+IMQwuwTfwD8Lta+mnv1EJf4Sax91D0L4A+xJsrsrt/bCoBvwZp4/MR6mV/CmrZAiGcU2tO+yuXc087Vrz/D2v7zgXVPui9jbVyBtXH4KwAPYe2rzA70ld0lw0LQp3dCnA8z+yUAu0MIw3wFKIQQ4mmOPoESgmBrcZ5uszVeiLWvEP7sye6XEEKIpwaKOioEZxRrX9vtxdrXCP8ew8W6EUII8QxAX+EJIYQQQuREX+EJIYQQQuTkog5QZvZqW8sD9oiZXSpXUSGE2Ba0hwkhLpQL/gpvPd3FQwBeBeAY1vLtfP962gtKYXQkFGcmN9kq5T4t2xt4eRbraqU0cLYsmC8IIJwt+bLetDnE2KYGhrOx6iFyVGX2QJRpVsy8EUDIyNVs+Dk1Un3oJZHGBoo1SkqlQ14nQiiTRvkwAWScrOwLh0Fkoki7dJhJucQvUQBASlKKllZJkxGlYmxNufrVyIQOyJiQOQkVNnm8zaS9uVP9pXkMWquxhfKkkncPKxdqoVbcEkIn9rBk3h4yvzgsGe5ZicKuz9oEgKTgq5f94kqrfmHRfRIA3Wovdrbz1B92T2a2yF6RkFeSDXwDFpl7S4m9Txol8xGb/FAh767i8GsnIX1icxcK3lho8Q0slH3/bZUEbo++Jvw6Y+sxRlbx12frdNh9EuBron362FwIYQcrfzEi8hcCeCSE8BgAmNkHsBaNNnqAKs5MYs8v/ItNtuv2naFlHz8z6WzpwA/Y9Xt8/Wa/TNtM/3Cns7V3+tEdRHJlsweLPmxkEtIab7M35hd2f9I3UJziGQX6HT+FxcrwJxMjO0sgT1ZGDkvZCt9VjT2Z5GVdWeArOysO9wbp7+86W1jlS7qw6tdO4YA/rfTn+EQlHd//pO9txRVvq57l97N0k7fvusuXa5E1CgD9c4Up3ED7Zr52Cqd82Kpi0/e/e52vn0TmqHLf5vE7/N5fHaaLTxa59rBacQz/bO+WfNQ9/gtg6Pi1mTX9ektqfrMJaY7fLEhZK/P9z8ZGna2/f8bZlq6vO1trD38LpiTyWUp+sTH2ix6AkLADIC3KIXttgT2rZEiL5JcVAKif9o3Wzvh5LnT5PBWafu7t+GlvGyUZXcghGwC61/j3d2uXn+dCL/JcLvj+pxU/0N0Jv39OfJG/o3t7x52t9LkHnc0K7KAIgKz9bL9/R4MdSAGsXO/Hb3W3vxZ798YOVWxN3PsbPxNNBXQxX+Fdhc0BuY4hXx4jIYR4MtEeJoS4YC67iNzM3mpmd5vZ3elK5MgvhBBPQTbuX71UieqFEF/jYg5Qx7E5YeM+fC0R5FcJIbwnhHBHCOGOwuiQ3zkIIcTl57x72Mb9q1yIfA8vhHhGcjEaqM8BuMHMrsHapvN9AN54rgpJIUOtsfn74dll/708AISMCBl7/vvNR07474ZZOQDYTb5ebhz3xqTPv3Ptjfo+MQ1Ae8Z/B88Ew0BE9FbyfUpTftZNSNliiegiIqLfQoEIqYmGidVPRiPamsS3yZwCerv4PPXbZFCIBsuYBosIwwEg2+l1Cezqtd1NWr+16F+eWYHoxxKvSygTXRQAHPxIz9kGNd8rr0hZY3WPXxM98jjVHogsPkLrWq+VKJ70i5xpSgAvTI34czxVyLeH9QfITm3Rg0T0HTEdkoPUj2lGQpt8AsbKxjQnRC+V9L2NOS2kERE50zuxX8vTUsTpgKyjjHQ/RDR3RrSVGbkW06pmpdjiZHutH4BSi49zqeTrl9sTvmCL7J8l/kquHGI6JP/uKzb9ngIAc8/1G8PMF5b9dc76MVn4OqqfxvgDK862/O3Pcbaxh/x1ACA56+3JMlvj/N1Xavq9vtT0ZZkTT8yBoNji9hgXfIAKIQzM7CexlqywAOB3Qwj3XWh7QgixnWgPE0JcDBeVyiWE8FEAH71EfRFCiG1Fe5gQ4kJRJHIhhBBCiJzoACWEEEIIkRMdoIQQQgghcnJRGqi8ZJmh097snbJnZmno+s1l79mSdfwZsLjMvSPqp72HgpGUC52pWN4Cb+qOe6+F/qgvmNa4F0lWJ24oxLsra/OpsrKv31nwXldJjYfjL1W8faTmPdaqJGVOucBdsYrEC69LvPAQiWqxUPEeb6zNlaYvF/M2TIi3IfNsZF6JAJCQ6O4s7Uu624/d0jT/PSWteu+2yYf8ODeORqLQ18n9s4jxkae8tYdEjO75vtpBH7+teieJogzvVRXz1nu6EPW2i3gOufpjfhzDAt8Tk0niyUVgUdABnkomFuXZX5ybaYoXVjbi9TSsx12IOBYyjztGOuLLDYgHHwCkVW/vjfmbYh5fAFCb8/ZqbcrZysskujmJYh6juDR82R13LzrbyvVjzjZ+1zFnGy3xwe/s9f7BzDMuq/ANKGFR9IlnYqhzL+L6YX9P/YYf57RHsmAs8wU5IHN/LvQJlBBCCCFETnSAEkIIIYTIiQ5QQgghhBA50QFKCCGEECIn2yoiLxYyTE9uTpXRKHMh3OkFH3re+kTgRTSEjSNcCJaREPuBHCFZyhYAaO8g4sIJIsQl+rSECNkAIKt5e0KE3ZZwsWS16oWI5UlfPyWpcQCg2/NLgKVyWWh6weBIlacNaFT8nJaI4LxS4ML2StHb232vVi0SwXenHxEsEnF5f+DFkUlknHdO+7QDbEwHRJjejfSpc7u/z9lJLwyfeJDnYGuc8PX7I/76J7+Rr73yAunrLr+ekoe82r+zMyLW726+FhMJX7Ek5kTjocefAWv4MbOyX8NhleSOIOVi9jz1reTtWZ20SbaKmCMCE3xnFbI2suHFuWz/ZH0CAERSvPj6RJhe4ULiHtmTrUEcRur8nvpEcN6ZIs5OLT+o44ci6WGW/Z6arHpbNkJyiwFI694+9pV5Zwujfp8vPuyF5QBQnPJODe1rJp1t0OCOFp07Djhb48unnC195DCtb89/lrMxEXs65cc0JhZPyxKRCyGEEEJcVnSAEkIIIYTIiQ5QQgghhBA50QFKCCGEECIn2yoiLyQZxqubI422+lxgljHRMzFVTnuB2NgRLk7OSl4gxsRkAx74lEbdJXprgOgA01okFC8RN2dNdiFefXXVl221iVg+JraskWiw5J5KJBL5VI0IWAFk8A2UcoSkHi35aLQtIiJPiTC1TAToAI+knpHJK0QimfdSP6mrHb92e10idi/xe6/VvQh0dZ/v02LgC3JQJQ4Aia+/59P8+idf7Ndk/T5/rZToUtNyZJx2bx7nMGSk6CsWEk0ZANDzYnxalpUrcCFxWG5647QX8loaC/vt7db3fRoQcXRs/0gbpE0SDT9EMiFY199rIBHCY4Lv2L7oL0RMZd5mYIJ3ck+9aV6/uOjvKSWvuZET3rayn78PLfP2+mn/rFZnfdYAAFi5wUe8H2/5tcfWg0XWI+Z9JPBqzfczRCKZl7xfDqWwY5r/4OhpZypX9vrrF4lTAMlAAvA99VzoEyghhBBCiJzoACWEEEIIkRMdoIQQQgghcqIDlBBCCCFETrZVRM5YanOBbLrixbilZX/e2/l5L04strmwc1Aj4r4KEZhFhImDmv9BsU0Ej0SDWJnjQrrODIlmPeXvqTTKIx4Xil7IWJzx98+iiwNcdN2o+GvNr/oItY+dmqFtWuL7xCJ8l8vDC763Oh8AwCiJYp9GQxZ7dlS9KLeT8kdiru1FmCuZX7tGFk+BREwHuKNEseznrjfNx6m3TCJLk+4P6nztFVdJX0ligN6kLzeI9Kkxs1nEmpQi4t8rkSxEI49vhZXbGsUcAAIRlsdEu1nTC4QTUj/UIl4woz46en/M92ngi6E/xufRqv76xRyZFPpFEgm94++fCdOjsEjmRITO+gkA/TaLzk76H7kn2iXiiLG6z9tGH+P1a/O+/8xhpHXAZ/AAgPGHyV631+/p9ce8MDzs5iLuZJk4EfXI3Lcjz0zB73/t6/w7pXbfcVqdReFnIvjqqbazLV9HFjmA2hxfEzH0CZQQQgghRE50gBJCCCGEyIkOUEIIIYQQOdEBSgghhBAiJzpACSGEEELkZFu98AZZgvlWbZNt+Yz3bgKAMvFa2/U5r7BvXuXLVRb5ubB61oeuL6+Qfla5F0yhRzzuWNqWivfO6HPnCIq1faN9lk8DQJ85pxDnECPpEQCgS9K+LIwRz6C6905gHoAAkA58/1l2hO4qT1uwQjwGz9iYs9VGvctYtUxSYwDYO+bzBhRJeplGJOXMat+Pf414KzbJPPW6/DFjnknFIvHCi3hQ9keH8wJi3joAUGp6e3u3b7NylqQ72h1JY7HFA5OlBXqmwjzuaHoX4p0EAEbs3NuPpIICkI16r6veuF+b3YmLS78zIOs9Id6lAE/bQr3bIl54oUDKxtJmbYH1EwCM7WuRvY6R7SOeaLN+Xxj46cDSDZH7POTnvrnP2yYe4n1a3e1fQI0Tvp8rN0+RupH1mPk0QhMP+/VYbHIvPJZOJRmQd+e1u3l94nHH0sZkJd//0SPeqxsAehP82YmhT6CEEEIIIXKiA5QQQgghRE50gBJCCCGEyIkOUEIIIYQQOdlWEXkIht5g8yUtkuqhsuDFdGdv8d0de8kpZ9tZ92HrAeDBT1znbHs+4wVuGRGiAQDLEpKViBB41fc9i2jTQpGl0/D1+6P8rBvqRJxJRJiFcR6iPiFpRpK+v/9qzY9TvcIF242KF3c3u0REmfJ7SlgqGKKtXGr6lBULC15sDgDLK16xWakOf0+dvl97Kel/terrs5QtANAn4zwgAvzCKO+TnfJ9KhBtZH+Mi4KLLT+o1TNEME7ErqHH76m0RQRvzKPhCiUACOlwYuJhtfO0vTYXuIKleGGpXEjKFwDo7PYT2dpJhOlkT2I2AABZB1b295R2+KsmIalgsmYOIe9FLK/APFvAnTuYrVbn4uhOh/R/r5/TbMk70RRIGhsAWDnobWOPkGtP8Xuqzvv+Lx/wc1Kb83MXa3PiETLPNb8eymf5uyerEGeDrl8PSSeScmeSpNIiwnRLyTv6DPEeA2B9stmdA30CJYQQQgiREx2ghBBCCCFyogOUEEIIIUROdIASQgghhMjJtovInUi2ybtQIaK38vd6wXir64V4p8Cjm5duX/B9+qwvm1a5aC6hmkEium34vrPo5ACQVYiIlIgwLSLiZCJwFiG8WOKRgBs1L/hmgukVEjG+sstH9wbW5nkYekQwDQBlsiSqJOr3s/f49bAywyO2F82PybHF8fP08GvUSITzesnbtkbaB4AuE5UCyEh05XKVRHyPCNt7I/5eG0d9mwkNVw+MzPoxae3yv1NV/GMDG/B7OlPcPKZMFH+lYiDRwJmwG+ARxoe9TplH6AeJMB6W+DNI2yUC29W9vhxzeLEav59YhPGtpC2+zwcipKbJFVjEcYBnXSD7X6nin6sBceIAgALZU1nUcuZEAnBHEiYsn9jr526xwFNWFJZ9X+df4q9TmI2sHTKqpZYfvM4UcYwh72IA6E6Qd1/Vj1O/zh17Rg95Z4e07u+zN8XvqdAm7zkS9Zw5hYUab7N4Yp7aY+gTKCGEEEKInOgAJYQQQgiREx2ghBBCCCFyogOUEEIIIUROdIASQgghhMjJ9nrhpYbO0mbPoWKTn+HmX0FC35+Y8gVZSolIehhreTV+fdp7EsScyBLiDJX6aPLUW68/zvuUkDQdFeLFEWNm1Hsy1Iq+/lyLh6hnnmSjJBVLt+u9SFaa3uMMAJqrflBqJBXMCEmlAgDlwnCePb3Mz2caSZuyp+E9XnbUfMqfLDL5lYL34lnq+ftcIV6hq8TbDuCpJPo9kt4gMh7ZjJ+77qT3zCu2aXV0x/1YdXZ4j5vpL7H0CPyeOktb+h8pd0VSSGCNkU2mEEm7wjzpQs+v90C89azKPUmpF16TeBj1+P5Ravo1nFWGS5sSBnwes4Skglkla7jDn0sjSzsjHssWSbsCYg/EMzKp+TGZGOcpb2olP07Hybsni/WJfC4xOuLXybNmvBfxIeLtCwCnzxJPtoG/zoDsCQDQSf08k9chJu/3trnncy+8MOLHad9/841mkVNGZ5d/f5Tn/TNS7kfe533y7JC0L70d5DosNxgAW415MXL0CZQQQgghRE50gBJCCCGEyIkOUEIIIYQQOTnvAcrMftfMTpvZlzfYpszsY2b28Prfk5e3m0IIcWFoDxNCXA6GEZH/PoD/AOAPNtjeAeDjIYR3mdk71v//s+drKOka6o9tFmm1b+YizISE7rdFL1ArLbHUE/y2xg950dnKVUQEGcs+EckmsJWUaEBLS7xRm/N2I+lAWHoYADg66cXhTJheb3hhOAAsD5l25da9J5zt5CoP0V8teiEfozPg8zRS8kLCQfDz1Cci8qkqF4Yea06Q+r7NZocLeFeJMD6QKanViVh+lK/xVisiFt5CIZbGgjkbBN9meTmSimHcz31l3ttmX+mvs+NTXHxc3vI8MpHwk8Dv41LsYWaw0ub7Dk2+3qIpXoYhVpeJw4kIvbBrB60++3y/V1g63KZmRBgOAMmit7FUMLF0QlmJXJ8Jw0l6KwAASbvCGK37Z5ClAYuxe4/PZ3TqlN9TAKBI0saU6n6eXjz5iLMNwo20TeYcs7ux4mwPn+Zz3yXzV170bS48y89HbZZ/zpL0/fjVZv3zUFxs0fpLz/HC/Noxv3+29/HUbPUHl5zN+n7sq7PE0aLE7ymd4teKcd5PoEIIfw9ga4KY1wJ43/q/3wfgdbmuKoQQ24T2MCHE5eBCNVC7Qggn1/89C2DXJeqPEEJsB9rDhBAXxUWLyEMIAef4csvM3mpmd5vZ3YNW5ONuIYR4kjjXHrZx/+plkYBaQohnJBd6gDplZnsAYP3v07GCIYT3hBDuCCHcUayPxIoJIcR2MtQetnH/Kic8cKwQ4pnJhUYi/wsAbwbwrvW/PzxMpawa0L5ps5hvespHgwaAs/NezJV0vbiQiRMnH+Ii5uKqF/IVJ/0ZMq1xwSOLRM6ijjeOeVupyT+kM2K2zBsHVd6n9oyfwv6ot/WKJGQ6gPa1XlxZKPpx6ox5ZWgpGU7ACQD91Av5Jqv8N/rTq37uu31/TytL/oUW+vx3guI86f+KH9NBnc9Txuxk8rrH/DintcgHtON+QSUkiv6gz0XFxRKJxEumJBYJuLzi+1U55htoXv80iib+NXLvYWGQIp3bLKWyAl9vLOo4w4hgPIzyrAG24sW4IfXzFer8We8Rn49Cx88tW0MWiUTO1naRaIZjzxUVh7NLJZH9k9RnUdNXWn5MXnXNA7TNj3zlVn/5or/O9zz387T+Bz9/h7Mtws/pfatXOdstoyedDQC+cGS/s6VEbN9Z4HNfbJO9bsTfU+lq/y3R1TNnaZuMxaMHnG3ijM8CAQCllr9+WifC9GP8jNA94EXo5bv8nCYLRGw+zZ1uWzdyEX6MYcIY/BcAdwK4ycyOmdlbsLbpvMrMHgbwzev/F0KIpxzaw4QQl4PzfgIVQvj+yI9eeYn7IoQQlxztYUKIy4EikQshhBBC5EQHKCGEEEKInFyoiPzCsADbIgZcanLRGxa8mKxARORlok+rneDhElr7vRdgsePFiX1yHQAYEG1ndX44wXdrN2+TRWpmYvXaGS6iLJAA4yySelqJ3NMZH7k67PLi7rNtf/OVAg8zPVnxKtLWwM/nobNeBAgAg4G/gf6svz5bD8VWxAGAjFN/zI9pVo6IXcf8pIxO+vscqXjx8Kkz47RNLHthe0rEssUJLkhOB/73n8FOX3/iMT5PwfxY9Ue8beJLvp/7fuRh2uYjH75h0/+fIpHILwlmBitviUTOooMDrlyMpOYdIRZun6ZlJ77it2tb8KHAT75q+JBWJMA/hQmOAcCIkLm0PLzTQWj7Zz2r+DUc7WeX/KDi+8rE1Z8sXc/71CEbaMO3+YkTN/hy4FHbB13f5t88fLOzZb2Iw8hJv38um1879SU+9kzYz+autzTqbPfv5d6nhVU/9vZ1ZP/4JH8f1x/0tsEO7+lgR2Zp/cosecau2u1M4bivbx2emSMr5/tMSZ9ACSGEEELkRAcoIYQQQoic6AAlhBBCCJETHaCEEEIIIXKiA5QQQgghRE621QvPDChVNqdZ6c5zhT8LPV+Z97Y9n1rx10kjqTOiKY83E0u7kpAUAcvX+nIp8diySIoRliLBSHqarJTDs4U4cjAbAFRP+371et7jbbbtPR5GJoZPrrrS9V4kIfB76q0QD0zi7FReJKl9Yhk02PCTaU4bw7uNpelwv3/s27VA7WdqJGXNST/2GfGWAYACSS8xmPZpjFb2co+wsaO+bEj8PfW9Yw7qRe59Vj+1uU/Mo/RKJYTgvO7iqVwu/MZjaZtaB/xErN5xm68fSzlKusq8TtleMXUv71O56ddgVvRl0zKv35ki+7x3LKTXAYDOBFmvDX8DzIO62SW5bQDqxceYX+IDzVLhVE74Po1+1r/7anM8DVn98Jw3sjQ+Ee/P9tV+7czf5MtW7ph3tm++6lHa5uFV7y262vd7N8bJBgIAZ/y1Sh3ixfx6760IADv+6B5vbHqPv6zt05VZg89dbJ3G0CdQQgghhBA50QFKCCGEECInOkAJIYQQQuREByghhBBCiJxsq4g8ZIbeFjEyCwcPAGUSkn7nF7wY7GJhggvVwTwAACAASURBVL8koiNe2U1SfxDBYWHZD2sh0vXKAhFCEx1hTNheank7E8J1J7g4LvWZXKhYP+l6weFqRJRfIile+qkXUXZaRHAIoLDox6+86NdJRqpHdOmYesD3qXrWC32ZABYAsoq//uK1PkXL7HOIWrXEB8qICDyQ9URTSwAojvp7Ks35scsiWUWWDvqyE4/6MWle5Rv47J1c2DnW2Dx+MeeFKxFDXDS+lYSIVNMln3fK4Mc2lrZk8Vo/XywVFUtbFGt3+h5ff/Tw8M4hxUWSI6RPNrCzRBkOAGQ8reTHJJueoNXLu/04N6/yG0NGUlnF3j3MN6RQ8M9lo8439fllf/3+qL/+ykGSSmWMP6xL1+4gbfpy/VG+1/QbxFlgxAu2R2MbKOG28ePOViK5mz6944W0foGkWGFMfZmsMQBWIGmAiGC8MO6dBVrPv5q2Gdv/Y+gTKCGEEEKInOgAJYQQQgiREx2ghBBCCCFyogOUEEIIIUROtlVEDguwwhYxWyTKcnfGi/aKK170lix7wWOoE2U0AKJvQzIYMjw5gFLTnzdLq17IViAazMZJHt22tcPfPxOMd6YjkXyJvXaGCEOPcWV8c7fvvwVfv3rG112scsFjSvpUKXlxcqfAReQJicROI1oTW/Usn8+FG/191k/5+YyJnotErM8ieRfb/pHqjUUirk8MFwW6N83nzszX7036stP3DP970vLVxAEiIkqm9V+6efGnfzVcVOenG0wwntSqpCDblHibhZ6fb+acMvUVLgJPujzK9VaWr/PCbOZsAwDVEeK0QBwuQuJF0AAX7banfP1CJMMAizDOnGhSslXFnIUGJX+z9arvwI9d/ylaf+kaH2H8Dx/xQurB5yedrTbHB7rc9J2tf+YRZ8tIJG4ASL/+Fmc7+WLfz6kP+bH7xK0voG2+5Hu+4GyvnvDRwf/o1d9E60/vu9XZysvDPw/db/KOLEbe52nVNxCL9p8XfQIlhBBCCJETHaCEEEIIIXKiA5QQQgghRE50gBJCCCGEyIkOUEIIIYQQOdleL7zMkG3xUiLOWQCAfZ8kHiOpV9hb13tHZKPE2wWAZSztCUklEPE4qZ8i1ydOA9UFbyz0eKMnv923eeC/+j41TnLvsuNvIZ6Jn2k42/wt/KxcO+1tzAuOjV11jnsyjN7q3bYaJd/P+dM+xD4AmvqkT4pWzxAPnp28T4MR3+Zq4suOHuHjXFny87dwk3987CULzjb1Hj8fANCe8fWbV/k+DUaG/z2nvsN74bR2+ZQzADB2xK/T5Kwv157ytmffcZi2+YHr/mLT/186OkfLXYmEEJD1IhvWMBCPOytzT1QGTTtFvI7mbvPeVbGyvXGSToSkAyl0+HNl13qP5+q8r7/z0/65AIDeTu/xV2yxFCfcPTYrsmeD9J/sadkg4olVJF7QPe/Gd3PlBK3eyvyYtFov8X2q+uvEvMN6YyS91bN9OhK7815av9/w9f/1j7zf2e5pHaD1GXvKPj1PmbwQn/vyh2j9k1+43tkGdT+fvQbf/0otkvYq8WWZV2axw9/HrM1zoU+ghBBCCCFyogOUEEIIIUROdIASQgghhMiJDlBCCCGEEDnZVhG5DQyluc2XvPfNv0HLftvf/riz9SeJOLxABM8dnrIgI2KyrORtIUeU9+oKEYaSVCjHXsbTnuz7c1+/1PRC1SPfwoXxu//Qn4GbP+aFu6XPzdD6zRv8tWqP+76ylBH9BhdcV4t+/GtFcp1x0iiAHkkRMzjjhZnLU2TsI8LQyu6Ws43/mRewjpzkOSOKi14YXz3tx/6h5/jcEqsv54/ZxIPeRh0YItmGstRfv1gkKZDavAEmrmztJGk4yJD+z3vupG1WbPO9XpqECU8RzGCFSK6fLYS+X0chZXl6iBNMZFdma6O1y89XFtGls2cjI11qHPO2scP8uWju9c/q1H1Nf+1ZkgsKwMrX+XQm87f69TrzRVodKweZw4svVyTZbZJIephkyU9Av+r3tE81b6L1XzTiU6zsnvKpfZp3+r0iJPxZZX1lzgLpHS+i9Zdv9Q0wwfj/PvOPzvZIn6/5xYw7K2xlvMT3+ftv8O2WVvz9x9LbsHlmzw5znih2YpsqN8fQJ1BCCCGEEDnRAUoIIYQQIic6QAkhhBBC5EQHKCGEEEKInGyriHz/5Bze/T2/u8nWCVzwnda8wKwz4W3TsyvONhjn4rZBdTiB7KDGpa8p0XGHxPep3yBizQpXpy1c76dg1+f9mOz7OFc8zt1KxNXHJ5ytXI6I5kjU3e7NXnFZuNePaf8AFwdWCnxOtzLV8MJuAJiHF1e2R0gk3jEv7B6c9HUBoP+4F4zPfjPpZ48/Etb3YtlQIyL2Vb8eWGRlAFi6gUS2JxHfwxSf+wIRjPe6pP8T/PpsnRb8kGLpdn/9W8qztM0Mw0fWfjpjJT8OVvZrKBkbHbpNJvpngnEmDAcA9liOHfZrqNAjUft3cyeY1X2+T5MPEGH7kt+nAWDm034dDeq7ff3Im2rmHv8MLtzoByCwjwoiHx+w57V/xm/+Hz/NReTje/2+9lPXftzZfv4bvstf+2G+f5XI8PXGScYG4lgDACNTREVPuLPj3x0lG24/B4DZga9/++gRWvZTtec6W+2ULxeLDs6yiLB5Zus5Rijmc3vRJ1BCCCGEEDnRAUoIIYQQIic6QAkhhBBC5EQHKCGEEEKInOgAJYQQQgiRk231whtNMry8tjnMfz+SN6U14z0peuMk7Uo5xy0QMX6PeCi1d3DVfkY82brTvn79pK9bO8nPqsyL5tjLvWddf4z3KRS810Wh6a+V+iYBAMmyH7/iKkmlQpxDrMD71Or7m6pWV51tscW9JYtFf0979591thOHfHqa2G8ELI1F6bS/z/4E92IJDeKJkpL1SLwaewe5t2JCygbztlKBe6EMSIqFet270a3u5OPceNyPVoGkfSmPei+8a4rc1St5eiVvuWCShvf6DG3iCUVSw4Qk4gVMppF53KX1SOoe4kW8VCN7RZV4d0XSNpV81hYcf5m/d7zsDlqf7WvslVBe4mPSJOsw8VmjaNoP5nG6XtpZMuKEeOys9zgDgLkd3rNyouA981570z3O9ueZ90wDgOyonzya9ilHKpLPnb3a2eokZ8y3jt5L66+G4TxuRxI+0J3dfk+d+oof+16D7zWD6nBpfFgqlxiZvPCEEEIIIS4vOkAJIYQQQuREByghhBBCiJyc9wBlZvvN7BNm9hUzu8/MfnrdPmVmHzOzh9f/nrz83RVCiOHR/iWEuFwMo8AeAHhbCOELZjYK4PNm9jEAPwTg4yGEd5nZOwC8A8DPnqshA1DEZkFYYsOLq0dOktQVU15ZWVrmorX+yHDiwME4V+IlE15g11/wHV2pEMHyMr/P7rS/VhglguVu5KxL9HHpmG/TyhF14apfAlnB97/oNeAIGRfcsVQunZSksUiGVzwuNL2K/cYbTzjbscVxWr9PBNfVqlebXj++ROsvd72Ic6Xjlfmrq77c5DgZPADNtq8fyHxmkXEedP09teDbTCd4KobyPX5OSkREvnTIi4L/+/O8gB8AXjeySO1PIpds/8qDjfj1mjX9OsgW2Hh5cW/0OnmExGQLYYLxtJIj9QVpc8AE55E+sSwhkVfC8PWZvwcR4McylMTSxmylt0BU+QDumj/obK85+E/Otljza+Qtt32Gtjl785izHV6ddrYzLSLgB1Av+b3uurE5ZxsverH7bWUu4v581zvcXFc67ct1DtL6hXH/Pg2JH1OahidiL3b82ssjImfC9HNx3qUaQjgZQvjC+r9XANwP4CoArwXwvvVi7wPwulxXFkKIy4z2LyHE5SKXBsrMDgJ4HoC7AOwKITzhsD8LYFekzlvN7G4zu3vubA4fSyGEuIRc7P7VDzwchRDimcnQBygzawD4EIB/FUJY3vizEEIA/TIJCCG8J4RwRwjhjplpadaFENvPpdi/Ssa/shFCPDMZ6kRjZiWsbT7vDyH86br5lJntWf/5HgD+y08hhHiS0f4lhLgcnFcuZ2YG4L0A7g8h/OqGH/0FgDcDeNf63x8+b1swFLYqBAP/Wm/+eV6gtutT/rxnRHWbVvltMcElE6KFSITttEPEdCSadLbTC/a6M8OL0xrjPmJxTEhcJlG7Oz0vDu40edRYEvgaxba/Vn/UFywU+dytkkjkNSJi7LR5n1i7o3X/9UmPhGG+bsZHLAeAXkoiFpOb77PQzgAmqn5OlomIfHzMC4Wn61xEzsZkse0/5WgRYToAGgl9QKLIJzWulp2/1T8n+z7h11Mg0Z5fUPUCfgDIwKOeP1lcyv0LISCkPFL9MCTjPkI1Ur/WC0QICwApcU5hvwEXesPvNQMStdzoXhPJhECKZkSEHvhjhaRL7olEEmdORWt2si91hmwz0if2njAy7dbn4zxHhNyP9nc42/eOPuBsfeZFAuBv296xYGXg94WYiJztK4+adwR58djDzjaXkgj6AECe9R78oM71yboHYMd8/WTgB79f55/zMMF4eZntX36e0jKfu5hgPcYw/gYvBvCDAO41sydcCX4eaxvPB83sLQAeB/CGfJcWQojLjvYvIcRl4bwHqBDCp8CSA63xykvbHSGEuHRo/xJCXC6k6hZCCCGEyIkOUEIIIYQQORky5uqlISAgjYjGt/LRV/+6s73pH9/mbFnJnwELkcijTHQWEiI4bEeioyckymnDqxPrIz4ServlBccAYETI3Ov5aSmVuHh1kPm+dlb8tSwi+GZCSCa4ZBHTJxpcXMgE10ywPT7K688veiHkIgkl3I04CzDKiR+/1sALrhtlHsW+m/prTdV9//tkPk6tcBFlseDHNCP1swH/BspIFHmQNZpFHvMycRZYutqPSTrpIwbvKXCxeD9sHufhYwBfATRqyJ5/2yZT8XP306JLL9rnqz/WdLbk0aPONnqMPIAAzo57JTUVvUa22ECWAYvGzYTlbE/IAxOLA9yJhYnYByPDr6S04gegOkcGKvLxQeKXO41OXljlDcwv+f1rLPFOMDMFX27r8/MEq5nf09meVCnw+r2BF3c/Z8I7guwu+sj4jw+GdwzpE28BFpkdAA48/7iztb64d+hr0fc5EYx3x8ieSsqt2Ye+PAB9AiWEEEIIkRsdoIQQQgghcqIDlBBCCCFETnSAEkIIIYTIiQ5QQgghhBA52WYvPGCAzV4CSeQMd22JpKQgniBpxdcf1HibCfHOS4gXShIJ0R+6pF3ioJCmvtzYaIu2ydKuMM+8WCoX5rVVqvmB6i/zXAilVdIuc3iZ8G0yD8AYGcn5EEtx0ur6MWnN152t3/L3VIx4oYxWvGvNWMV7xrA0NAAwUvL1+yQ9DLvPXaMrtM0zq94Lh81z6PGcEyzlTkLSu/QiqYn6+/09LR/0Hky24Mfk1fd/F23z+rEzm/5/tP/faLkrkayUYHXvZm+o0dtuoGXHvzDrbMdfc5Wz7V3x+0LtUZ6OqHD9Ht+nSIoTBkt7wtKZ0LQnNb6GCmT/YPsn8/ZbK+xNgaTHYqlUACArkXvy2wdS4gTNUrbEYOlxWD8B/gz3iHca87iLpU1ZIl7IA+KCec0YXzujRb/X7a/OO9sra75P9/e4Z/LDfZ8KZnYw4WwPHt9F60/8g08vUyJexIVeJLURSccyqA5nYx6pwDnWaQR9AiWEEEIIkRMdoIQQQgghcqIDlBBCCCFETnSAEkIIIYTIybaKyI/2G/ip4y/dZPv7x6+nZa+e9gK35eu8GKx/yovzGie44pClbSkSbXeRCasBGBGH94nYvUPKoUGbREJEc0xEPhjws66RrqaRsowRH00fK1eTPpF+jhBhNsCF1CyVSsY6D6BcJGlXSCqawlk/9oslL8wGAHhtI0pEcF4i/QSAHhGMs7QvRkTo820vgAeA5RVvHxCxfyy1EHOAKBBhuY1HnCKI4NxYug9SbrHtBaAA0JjcPCbJ0yiZS1YAemObx2LuefzBLjX9Oqws+rE4/h1eGL7vQ4/TNlnaFiZ6jTxWMJYSiIiw6bUjjghpjTgdRFIPMQodtieTfT6SyqVAUsRkJJVLRgTfSaSfgQjzmeCcCdgBIOv4veLvlm92tquKn3W2R/ve0QAA/uGsd1ZY7vpncGedO6xMlbzDTp3krGllxBZRXB/tTzvbXN+nrSoc5XtFwevaKZbxcWbvcyYsZ91n6XqAuGA9hj6BEkIIIYTIiQ5QQgghhBA50QFKCCGEECInOkAJIYQQQuRkeyORB0Mv23zJl179CC07ICFyk2867GyzH7za2Vb289uqnSFC5DaJfEqEjQCPsJtW/Rk0I4LrQZ9Hky4QcXSp5JWhsfqWEHUj6X5xiY9Jv0FEnETc1yHRsNNIJPIWEVI3iLhxqcfFhc1Vby9UvLg7nSI32uL32al7wXmfiOCTiFiW0U39tVZ7/t67fd4n5izAKC9FHAiIgJjNnUUi64896Pu6ut/3qXHE15+vEVU+gM+WDm5ub5AjVPZTHQO2bF/oj0YyBBS9vTbnn9VBnYhe6/y5mHzIr9e5W/34FnjgaCqmDSzqeIE4F7AsDAACEWyzX8sT4twAcHH2oE4E36SfAI8QnlZIdHQiGI+NE43OTnxLYhkr0v6Ffy7xqeUbqf3h0zucjUU8n2+R1BgAmuM+FPvzG95Z4c9WvVNDn0RRB4DH2r5P00SsPsZf8e5ZAvj+VWrykPG9MfJOIo/OsGL1tT4N7wAB6BMoIYQQQojc6AAlhBBCCJETHaCEEEIIIXKiA5QQQgghRE50gBJCCCGEyMm2euGtdKr4uwc3h6RvjLdp2XbLew3c/dLfcrZXDn7G2WqnIqlcmHca8cQoRVK59Ma8jaUSCCWS8mWFeyMNiHfZoOS9C2L+WoNlP04gqTdqZyMeI8RroTrnbeVF3/+566Z4p8a8y8zjgxlnK5JULACQkDnpTxBPjJofu6TNPUZ6j/rJO3HAl61WubvPaNV3qk/SuzTbfj56Pf6YpWRMS8u8/4wieXSYZ1FCPJUAoHnQjylzuPnJf/Fnzvaf/q/X0TZPVCY3/b8f8UC8EgkJMKhtHsvyEn8yWYqo7oSfh8YxX3/xed67CQAm//6ws5WuvcbZ+iMRjzeW+od5HJeJFxzZUwCgV/NlA/EsTpOIJylxeWPpiALxbAYAkG1h5CjxjCZbTfVsLEWIt3V2DO+dZcQ7bnngveP2FrxXZTvl74k+8cJOl3zZfo3vqUeIx/QXxrwH+4tGH3W21Yy8YwAUiQf4R0/c4mzM0xIAih0//tWzfv/tj/I9ZNjURoxYn0qtyA8i6BMoIYQQQoic6AAlhBBCCJETHaCEEEIIIXKiA5QQQgghRE62V+GZGmxhs/At+TxPW/DDP/pxZ6ubF82lZS/YW93Fz4XVBSKOZKKziI6MCXQzlqKAqNv6ExHBIgn7TyXwMQ0jaba06AWHJZ9JBQCQEc3i3o8c85dZ9Yrl06+7nrbZnfBzygR/E49wsf/4F085WzZWd7Yj3+bTiUSyDtD0EOHwiLO19vO4/0wMnRARZa/rRZxpJL1M0vODUmz6iSbZEdYg67Q36m3lJb54+g1vKxIHiu8fPeJs3/1Lv0rb/K63/vSm/8/P02JXJJYBxS2pn2Ki1YFfrvQZKJM0FWP/NEvbDJkvm3gdMkDWABDZv8j+ERIm4uZtFhf92h5M+EExkkoFALKS70BphZXl9avzRIhMbIPq8CJwll6HidCZUxIABOYYRAawRcb+x3d+grb54vGHne0XPvudzmYLXETer3lx9nzf738n+pPO1kq5iPz+5d3ONlXz3hOzOUTkq3suLvVTbX44ETg7NwBxcXkMfQIlhBBCCJETHaCEEEIIIXKiA5QQQgghRE50gBJCCCGEyMm2isiLlQGmbzi7yfax1/8BLVs13zWm7/rrd/yKs73hrf+KtplVvHBsUPFnyEI/EvWWiCszMoJMyFxc4urmlAgWQ83brBOJ5EtsTDTMBHsAUCTC+mPftc/Zxg95YWh5JdJmezgR59I1fEzmbtvrbN3dXgTZ8LpKdEd5n/q7fP3iHBFcnuBODb3dXlyekejAIMLwwgq/zxIRjBvT1UeEjQkpG8h6HIzwMWkc9ra7/o//19lawV9oskBU0gA++ju/uen/L/22M7TclYhlPMI4g01ZiTyD7LlYeOGeofvERLO9cb7e2Nqi0clJXRIwHABfb8kqyaRAopvH+pRWfdna7PAicjam7V3E2Wg/d2JJSHaJ6px/rgfjvD4Gvuyptlf2f7x1o7N96MTzaZPHl8ad7ade4B2t/nHRR6YHgM8+fK2znVj1bT539KiznSVi8xhFMqGx6N7s3VnoEaeCSH0jHhA2YJHx2Xubv097jXyfKekTKCGEEEKInOgAJYQQQgiREx2ghBBCCCFyogOUEEIIIUROtlVEnjWLWP30jk22l330bbTsP/ycj3SckPPedFJztk++93dom9936BXO9vh/8EK+mGjXUi9QK/RY1F4meIxEIicCt5TYopHIU/+D7pS/VlbgDYycIE2SwLNztzC1KO8Si3rOol73xvmYpONE2Zr5/jdv9mGYrRyZPDJOacOXHTnE1bLdPomuPkoiQxOxf3mZjz2LDF1kUccjc8/WY0oC+d77g79B6xepXNhfrGF+QaSBj3Nli/PH8PGfrwACkGwRqdJMBuCRjoeN8M2EtADQnRhODBtz7ohFX3Z9IlNLfHrW2iRliy3yrEX01kae60KHOFdEHus+ccLpTg43zjf9p2Xe6CM+8n7vRTc72/Eaj9Dd3e/3pYWOf0/92pdf6Wzjf84F253neVv9Wf4679r/l7T+yx7+aWc7PDflbCenfHaHWsE74ADAw6d3OFt31juX7I84MA0r+E56ERE52f+ykp9o9twtX833eRZx/lzoEyghhBBCiJzoACWEEEIIkRMdoIQQQgghcnLeA5SZVc3sH83sS2Z2n5n9m3X7NWZ2l5k9YmZ/bGYXl0ZZCCEuMdq/hBCXi2E+geoCeEUI4bkAbgfwajP7egC/BODXQgjXA1gA8JbL100hhLggtH8JIS4L5/XCCyEEAM31/5bW/wQArwDwxnX7+wC8E8BvnautrAj0JjYr5ysLvOxPHP0WZ/u9A5/0bTLvtoiH0B8e/Jizvbx/g7MlxIsMADrEu4NdvuizflDvAoB7l1ifnGuNezIU2qRdUr03xcek5x0xkJV8WZqKIZLxplPzLjfFKvHkyPj5fVjXUEt8PwediBsFSbHCvC1Xr+buQrWT3mvDmGsP80pinnUASqvEC4VNZ8SDKS0Rb6Xg22Teq88ULuX+ZcGnRIp5trGlsdWDD+ApllZ3RzyEmCMs8QJk6VkAIEnYA0v6T+qT7CTr1yeegWSvMFIOAIpk/yq0fbm+z4QCAOiNDedZmJDt5/TXe48zAOi9atLZmGdyZZ5fq7vf2+ol34FX3/h5Z7vrRw/SNn9w173O1sr8h6YzCf8g9c3Pu9PZ3v+VFzjbfM97AQ7YYgYw0fB5jSp/5b2Vky5/9xQi9q2kJN1aHpi339SD/CHpTERyFkUYqmdmVjCzfwJwGsDHADwKYDGE8EQvjgG4KteVhRBiG9D+JYS4HAx1gAohpCGE2wHsA/BCAD4oRgQze6uZ3W1md2fNyK/iQghxmbhU+1e/2zx/BSHEM4Zcn42FEBYBfALANwCYMPtqeLV9AI5H6rwnhHBHCOGOpDF8VmchhLiUXOz+VaqQaLBCiGcsw3jh7TCzifV/1wC8CsD9WNuIXr9e7M0APny5OimEEBeC9i8hxOViGL3uHgDvM7MC1g5cHwwhfMTMvgLgA2b2iwC+COC952vIMh/mv9DlSuTZn7nG2Qof+ntn62Y+nP3WdBJfLRu8kK+04hW6vTEuJAs2nIicCTtZ2g4AGPgI/ygSwaUxdTG4OJOJOGNJNdIRIhgnIvKk7m+qXOFCvFLJ20Ok/4xa2c9Ts03SiaQkbH9E2M5gaVdiqTlYiP+EpPFJ/HKkAtZz2Yctx1IZFFd9n0qWTxh5KbEnP5nLJdu/gnnReExEzsThTETOBOMxwXT1jK9fWfbPaneM/17MHFYKLM0Gqc7TUwGBbLUsPQvongRU50jR5eHGDgBWrvad7Y+wFCG+bn80kmKJOAERvTZaeyIpSlb8xR4/7b117iocpPUZJfPvqZM9L4L/lbO3D93m3umlocqd7fJvjiarXu2/QN6d5SYfZ5p2hThblVYigu/p4fKu9Ov+OqnXugMAKovDCdufYBgvvHsAuEw8IYTHsKYnEEKIpyTav4QQl4tnrn+zEEIIIcQFogOUEEIIIUROdIASQgghhMjJsEGfLwmW+SizlSUu2iou+iin3/zGH3G2pOfFdYXWkOpcANg1fNECEQj3iWczEyLHNNSF7nDC9Bgs6nmfCHe5sBw0cjYN7k5CEXeZshpARkSkGRF8s3IA0Gp6wXhS8J0adEl08FW+pJnYfqtDA8CFtgAQyPUr86T/bDqjUZy9LSN670KPz11GBJft3f4G5lIef22m4MWhS5kXho4n3tMhjUT7L9jT+HcyAwbVzWNebvJxYKJrJhhnTiT1k3y+S63hBONMWB4rm1Z9P9l6i4m4mWCcOT3EROgMdv1yk4fjb6+SfYVE6A9sT44sVSYwDkXfJ+aAAwCh5MtmPT/3RxZ8xPN6hbxkAPyPs89ytkcXpp1tV4PHKjvV9C+qUXKtUx3vwVAkAnYAuPfQPmcrP9uPfX2W78lT9xPPKmKKicWZAwebU7aeYuux18i3fz2NdzshhBBCiMuDDlBCCCGEEDnRAUoIIYQQIic6QAkhhBBC5EQHKCGEEEKInGyrF155oY8Dfzq72bjMvQas7GPnVxaWnS0MvHuFlbhqP/S810GtOe5s/efupPVLLa/mb+4jXijE4yPiyEA93qpnvS0Wep55vBi5fixtgRHvOnauZqkQykuREP2kLHFiQ4hkP7JPXgAAGnJJREFUGGH3xFLhdCdJKpP28OkZqLdNDm/JUtNfvz8yvLdRSpZpqe3btIx7QCWpv9bIUT93b/rWH6b155/v00ucfqG/1g9+06ec7d/suI+2eai/+XnuhtjCv/JIBgEjpyO5frawss8/BMxDaOSk9+Ri+wwAtGd8Az3yXBd6F5nKZci6AFBa8fV748TjlTuC0uszr6lBld9Tdd53LK2QssTEnj8ASKvkGSRevDGKy2RjWyS2Mb8pzdQjHrMVb9+/d2HoPt3/6POdrbZv3tmYx91q33tFA4Ct+nsqkVRSnRnep/YOPwEjJ/xGX5/ledDSCvHCJntld3K4lC+A97I9H/oESgghhBAiJzpACSGEEELkRAcoIYQQQoic6AAlhBBCCJGTbRWRI82AxZXhymZeHBgCETz2vOI4pJEQ+22fpoLVL/R20PppZbjUHYO6tzFhORARLJLuR0WYRF/HRKiFPheLsnD4nQkiTCXXKXYiytIhdXj9ekTYHml2KxWioYylfGBzx9IIrezjynZWnzkGsNQ+pcjc0V9f2DQZH6eEzGlCxK7h8eO0/jRxypj+pL//u3/5oLN9R7qfthlGNucmOXLkD2i5K5IMSLqb10xrFxeoJiQjR2XRr7fysl9Eg3pEBE72kNqZ4dOulInTQ2eCOIyQy8fSnrB0QqyfzAkFiKQzImXZdWKwvSolKXOK5HWwBkuF5Uux9C4x0hoR23f9jT54nOcWe5DkHLPEtzk+6lOgAcCtNxxzttW+v6npiq8fE5GPPcRE3L5claxRAJh/NltU/lqjh/gGWog412yldtp3alDj+3x/NN+RSJ9ACSGEEELkRAcoIYQQQoic6AAlhBBCCJETHaCEEEIIIXKyvSJyBCDbIpqMCMFCQsSJCRE8lkjE3w6PXMpE6AkR6JYXSShsAN0xL3BjgslBnUTIJhFaAWAwQoSd0/4+mVgUAMYP+3st/N2XfMHAldmd17zA2SbvPOlsS7/txbKz82O0zWrVj19r2Yf9LteJ0hZAv+fndPQurwLd8/v3Olsyzvs0OOaF1Pa8W5ytPc3r90e8rTvl5zQlc19qRua+RiI2s0jkJDIzAKQ1v05o/TrxagCAQiQUvGuACNNJVH8AsK1tDin0vBIIRUN3cvPaZFGzAaCyTCJkE4eNlETYjgmmWZsjR73ot3jGOwcAwOIdu52N9Z9dPyYCz4iGnmUSiPmF9BvEuYN0PxYheljBO4uYXuJJMIYmeYB//tAnjxtzDEiP+k0l5XptlMmYsPtsj/Fn/YFn+/1zesIPQCnxTg2FhM/e1P3+3ZOVfKfO3M4dLcYe83PChOVZkWy+AEaPkHdf2y++rOT3uaijxdJwmQa+2k6u0kIIIYQQQgcoIYQQQoi86AAlhBBCCJETHaCEEEIIIXKyzSJyeEFq4JGjjUVfZpHICVm7w9tkgvOBF42VvnyY1i/svtHZWCTdPtPMRQLphhKJuF4kQroSb6B01wO+7FahPoDCzDStP/LoorOlU15IPfp23+YoIuPc9YMSSCTeEImwnRJhvaUkGu01V3nbGX8/aw0Qp4T7H/XXfuHzaHUWiXhA7ikl5WJzT8uSJR4TKjMB7p5PnvUFiUMGAISuF4JbmSzelDyjzPYMYKtzi+UQyUcj92+hwB8r1I76LA5GHGZCgf9eXOyw9UqeC9LNEoliDnAhM2uTRQeP0WsQwTV7VsCzLjRO+Btg9x5zFmJz2m8M/6qsnyKZILr+eSmeWvLX2TNB2yw0/bO6cr1Pe7AUibB9/e4z1O76RNIr7Krx7CGHSn7/LS/7Ma3O87FjEecZizfy9TyoeseksceJY82qfx8lZD4uBH0CJYQQQgiREx2ghBBCCCFyogOUEEIIIUROdIASQgghhMiJDlBCCCGEEDnZXi+8ACDd4iFhkTNckXjM9YnXRELCtFcj8fAz4l5CbKHdptUrC17NX+gSrwfisMLSGwAASsTjjJRt7eJeMM1vvdXZRu+bI9fhU92f8qH/Vw748aOeNf1IGoslP6YsFUMoRLzwWMoLMqXVBeKF0eYpRhKSzsQO7nO2VeLYBwDEOQUp8cJDIPcZWeLMC4WlMOqO8QaYt1A4dNTZkqlJWj80fSoHdn3mcRe2PsdP9Ml5tT59UrkgeI/IWEoII/ZAUqRU5v16Zd5ZAGAdXzaMknXd4m58tZM+7Ut3zHtyMY+3ZBDxAmbpUBrDefsB3OOPjSnzogOAlf1+/2XP6tgRb+zMcNe+Yot4zBEbS1sCANWHZp0t1P1edf/bdvh+PsD36R1f8uM3d5u/fnIz95h7/qTfF5YHvk8rxHZVlXs2f+mg7+vuj/l3T203fx8vXePnrkyWfmcHn/vutB+TVsd7ETeOkxRu8sITQgghhHhy0AFKCCGEECInOkAJIYQQQuREByghhBBCiJxsr4jcAGxNMxARo9LUG0xY3s2RIyAZ8rzIxOYAql885Gz1HT69S2u373tURM5ElETflmVchHnqRf6elg/ucrbpe/k4JakX2HWmfJs0ZUON96k36u0sFQ0TkK4V9iYmIh1UfJsrz/HCTAAY3LHTl72aiDC5Bp3Dbp/oHZkAHuCCSZbuoz/C1+3MPd7ZwWpeBBpWvXgYADBsGhKS7oimWgIRlz+NNOSWBRS2zE+pSXI5ASidWna2QNLk2Jl5b6vXaJuhSkTPZP8MJL0LACQPHXG27JZbaFl3Gb+sAABjh/3G1ibeEUSbvHZ9ckv9OllbkXRELEUMS33UnvHPUGWRb0AnvpGkM0q8La3wxZ1+j/dEqZ3wYzLzj77++CHuALBwk99E+hO+/6888BitX2LKesI9Z/Y4W3eKHxPYe445OtRn+Xps7fTrvLLox6Q3zve/3jgTh5M9feAXWfUsfyHHnEJi6BMoIYQQQoic6AAlhBBCCJETHaCEEEIIIXKiA5QQQgghRE62V0TO2CoqX4cJJq3txWihRYS0RGwOAKFHFMIlLw4MJPIywDXDxS6JJE4E36VmRJyWDic4JxpGAEAgt1po+2sdewWPunvDbx9zNrtlv7P1Rn3dmIjSSNRiJhYt8oDv9P4LZJxL5D4XbiKR4QEUiDaTRQKnkwzAiFaYCevLy76BAYnMDACN497W2un7Xz/Dxa7FB7womEXmRxpRxhNhLhOH095XIsr4rYLz8PRRkSfdAeoPb460HEYi6uglEhG6uepte7xzQ2zEjAnGWcEeF8hmbf8QlJu+TSa4ZusfAFYO+I1pZNbvn4NqjueSCctHIpHM6VZNIr4TwXivwd89Iye8rUj8MEqtiIi8zNodLjvD7Nfz9dQf9dd6zm2PO9sqEUwDwOH2NLVvZabub/TO+66nZYssEwPJeGF9/j5NyJpi67G0yueJrYn+mC/X7ZB37ICfEVi2kXOhT6CEEEIIIXKiA5QQQgghRE50gBJCCCGEyMnQBygzK5jZF83sI+v/v8bM7jKzR8zsj82Mf/kqhBBPMtq/hBCXmjyfQP00gPs3/P+XAPxaCOF6AAsA3nIpOyaEEJcQ7V9CiEvKUF54ZrYPwHcA+LcAfsbWXHVeAeCN60XeB+CdAH7rvI1t8cox4gUHAIGlimC2AvfuoJBr0ZQUOdoc++Kss519lg/ln/QjHmt9f4Zl3mHM4wsAqqd9/1nqkIrPGAEAOPruhi/7F76v3XHinRVbPWRI21d5T4xCk99UeYl5MXrbmZu8rXqGd6lHvDOYB0/MY65Irs/uk3nrpMQrEQCSvvc4KRCHufopngqBPTuBpF1x6VWeqE88YEOfeHANm/LlKcol27/MnJdRstjkZVnaqAN7fZMrfsHQlC0AAvNw6voFkzFv4wgjR/31+3W/J1hkDTBPsvaU3z9HTnNPrH7djxN7XqjHLIDBiLcF5ohajrjXEkpkStn9s5RXAJAViScu6WdKXn2d3XycQslf/+jihLPdMM03wEfO7vbX6vtBfc4O/z4bv5e/o1evImuCpBEyss8B3LMz6fmylbN87QXiRdwfYWl8WBoxPnfFVj5V07Clfx3A2/E1X8xpAIshhCeG4BgAf2oQQognH+1fQohLznkPUGb2GgCnQwifv5ALmNlbzexuM7u7l/FEiUIIcTm4pPtXGknKLIR4RjLMV3gvBvDPzezbAVQBjAF4N4AJMyuu/xa3DwAJCwiEEN4D4D0AMF7acWV/FyCEuNK4dPtXbY/2LyHEVznvJ1AhhJ8LIewLIRwE8H0A/jaE8AMAPgHg9evF3gzgw5etl0IIcQFo/xJCXC4uJpXLzwL4gJn9IoAvAnjv+auYSzURE7gywXhok7QtVRL6vhsR3bIUL0SI5tJRnKNP2clTzlab82JRlp4AAApdcp/kWGuRYWIY+T2ZCSsBoHu/FyLu+YGjzjaS+rFb6fKbKiS+A2WS3iZGp+dFi/PP8bbyV+rOxgT0AFAk3x4zYXmIpXJh488+jyC2yiJvk6XMqJ8mqQzuIylbAATm7ECeJ+ooAQDseYg9j8Oy9Xkaftq3m/z7V5bBWlsWEhOLg4vx2XwZEYbH2rR+vjQTrn7ZP0PJvFdMF3pe8RwTcbN0JpVlL4TujvENqLLoy7Zn/MWKkbQpTEicEc3zoD58ei12ryw9VxLLkNTz7bKUNfzjCz5O7av9eioV/dgtdWu0/txZn4vLyD59quHLRdOQMap+Aw6lyDMy5Okj9u6rLPh+ZSWy4ZDLx5wKBsSp4VzkOkCFED4J4JPr/34MwAtzXU0IIZ4ktH8JIS4likQuhBBCCJETHaCEEEIIIXKiA5QQQgghRE4uRkR+STAiOgMAEMFkMHLeYyJwZgNgFS96Dh2v7mNiSwA8QjkRfI4d9oK/+Zu54DrpeiHcgERTLbT5PTHBZGnV1zcSMRgA+tN+nA/dtd/ZWHTw9m6u7it0iDD+au8AUHjYi8ABIBR9/yefe9bZVoOvHxPrM8FnVvbXSXoxFbk3sX4OyC2NHuXjtHQdWTufWuHXZ10iIvDQI5HEY4ThxKGBlLMQUXYmW5+Rp66K/FIQFpf5D6a9c4aRKM2BRIMHswEIJHoyazOZmaL1B0dP+PoTXjCeDMi6rg7/u3av4ffJ2hm+Lnvjfg0zETcTqwPc4YbtAYMai0ZNm6TZBApEGB6rzzNJ+Ov3xkgk7fFIxooqyeSQ+A48fHwnr3/WD8rYtd675cxH9/nr8G0aICJ0tp5jUezZnlxq+vdRsRM5phBhPlsP7Z3DRYYHeGT9c6FPoIQQQgghcqIDlBBCCCFETnSAEkIIIYTIiQ5QQgghhBA50QFKCCGEECIn2+uFl5jzugu1iBdeRlJSMO+4ovf4CG0WN5/DUslEvfBIihdalqTOiHlsMO+21YPe46LU5CH+E18UCcn4EEs7UDvi+9/Z6RsdjBDPuhq5OICMeDjYvJ/nwVW8U4W6v4GlL0/7cmxIIo5lzDuOkZV4Ax3iGdk4HMmPs4W52yNeocQ7pXB6wRdk6YoA7kXH0rPEPOZYWeLFx9f4M/B3rxDo+FBYihaWioWlbbnIdDqDXd4DEACSuXlftubnlnkylVq8T90xX7g7QdKrFPmeWj/lx5OVjaXeKJM0I50psv+SrapP9rS163sbS+USg6WTYl5fnRny7pnmach2TXtvz0qB3FSkn9m4X3tTI97dsPLffZunXjpD22RjStd9BDbO3SnvLRjzjBuZJe/jzO/JsXlmyAtPCCGEEOIyowOUEEIIIUROdIASQgghhMiJDlBCCCGEEDnZXhF5FhB6W4TDERG5NUk8fZKKhQm2EROBE9GssfrMBnDR7pBi2tHjXHA9qPhrdad8m5WFiLiZCCZLJBtITMTO7NUzRJhPhqS7M6LYZmYyTNaOiLAX/PwlXd8BJpZnAlgASOskbQvRA7PrAECPpH1h1yqukjYj6WFY/5GSdcLWPQB0I54BW4mkUrAySW1EHCV4m3w9+1QuTyMCELY4t9hIJB3RsG2ytC1MbA5wwTnZ69I63/+KY6PetuBTLIW9EcceAt1XSPcHdf4MrO7xa7Dc9I3GROQs7Qx73vqR1B0MJgJn6bHo8wsgJXs6I1TI4A34BnZ2seFsI3UvOC9WeKfS1Ld75O6rnO2aCf/eLRGhPgCEAkmRMuGfh1CMpCYip4/OhN8/0ogPDXunlJt+X6qe9f2MtZlKRC6EEEIIcXnRAUoIIYQQIic6QAkhhBBC5EQHKCGEEEKInGyviLxURNgxtclkMcHksOJuFkm8FBGRs/osnDUNcQ0aiZyJQOtfOupsi994Ne8S0ec1fHV0pocXt/XGfNkCD3BLxelMSJeRIU2ODy8YjonYGexaILfPhO0ZEXvHrs+uk1Z4/fpJP89MXNmeIYLFGm8zWSY3UIspJglknbJVEmLRgdl6HlYEHhORP60JTuQfxr0wO1q76tXJxpwGIvMV2HwP60gAoHnHAWdr3HPS2ZLBuLPFIjQzRwr2rEWdO8hy7xKxfCwSelb0/aou+rLFDhE8R4Tt5WX/vLKsAYMqv6likT3vxNlnwc/noMH7xN6Sy7M1WpZRu9p7FnXhB//Qa70I/MDf8DW2csCv55WDvk/Vef6ON2JmUeyZowAAYMh3SrHD5pOPc5cH8Y+iT6CEEEIIIXKiA5QQQgghRE50gBJCCCGEyIkOUEIIIYQQOdleETkAbIleaq2IiJwJuVkkXiIip+UAoHiRUZKZCJ1EJ88WFv2lO17ACQCdSSJCP+3vqUsitMboj3lbJBg2kgETjJN7IivFIjpiGuU1IUI+cm0ACESEaelw/Yy1yaIGF0jU8X6DKxMLQ4pQe1O+fkxAe837vLdAqEQcIAhDuxVEIpHTyPxkPQcWgb/PJ99qW0Sksaj+VyJmzkElGnGcOMcMPRIRxxpanznRpLxXCzf4+W7c7cPxFzu+zUGV7z9ZJEj+VpKY1p08G6zNbiSadWF4Db2jOs+fdSaCL/S8sT7LL97c58XVTOxeIk4kxRYf50HT33+xRfafZ5EMHgBaR72zw3O+4ZCzffmQj05eOblM2xw5MeP7SZwNOlP8mMHGeUAixsf2dJrdgkWmJ7ZYZPs8zk6RLgghhBBCiP+/vbsJsaqM4zj+/eU4M6aljtmbSiYF5aIMIoxahBCoveiiRdHCRcsCgyCKIGjZppdFm6ioRVT0AoXQokxol71ookllRVRaJiZlTo7j/FvcUwye55bHmTn3Pg+/D1zmnmcO9zz/c8/5zzPnnv99/osHUGZmZmYNeQBlZmZm1pAHUGZmZmYNeQBlZmZm1lC7VXgRaPyU29yPjabXPbv+lfBxVuLO+b/qc5RobpevuJ9qRZDq402lqkPm1r8Of97O/enXXHVxrWlidr2f879LlweMLqpvf/T8xIqpOWOA8XpXkxV3E0OJ6rJEG4Dm1Cu0Yiyxn8a7jN9nJ143UYWnxGt2q6JIHTsnh+v7ZOGe9DEylviK/7H6jBfMGk1MRdCtBDJV3ZaarqPbdEepatOJ1L7rUi6ZmIaIRMWLEudNalqRauVTltOr5Um19ycG01WTSuSllBhMnGxd9q3G6hVzE4vqJbcnh9Ln1Z/LEufwOfWyp8HD9eqyoxcmEgWnP23L2Pz0gTAw2rWO8X+3AzCeylWJirfUdB7dDByrny+pysYT56b/fA4dSeS/xD4ZPlxv+2sk/d4dH0lUHK/4s9Y2a1+ijA24b+O7tbbb5u2uta3bf2+t7cd1i5Oved6u+jF++Mp6BWK3achS04idmFtvGz7UJYmkjr3Ee5+cxqvLyGfg2OkfJ+ArUGZmZmaNeQBlZmZm1pAHUGZmZmYNeQBlZmZm1pCS0zTM1MakX4HvgfOAQ61tuB2OKQ+OqV2XRET6LtTMTMpf0N/7/Ew5pv5XWjzQ/zF1zWGtDqD+3aj0SURc2/qGZ5BjyoNjsulQ4j53TP2vtHgg75j8EZ6ZmZlZQx5AmZmZmTXUqwHUsz3a7kxyTHlwTDYdStznjqn/lRYPZBxTT+6BMjMzM8uZP8IzMzMza6j1AZSktZK+lLRP0kNtb386SHpB0kFJuye1jUh6T9LX1c+FvexjU5KWSdom6QtJeyRtrtqzjEvSsKTtkj6v4nmsar9U0kfV8feapMFe97UpSbMk7ZC0pVrOPqZcOH/1p9LyF5Sbw0rKX60OoCTNAp4B1gErgbskrWyzD9PkRWDtKW0PAVsj4nJga7Wck3HggYhYCawG7q3em1zjOg6siYirgVXAWkmrgceBJyPiMuA34J4e9vFMbQb2TlouIaa+5/zV10rLX1BuDismf7V9Beo6YF9EfBsRY8CrwIaW+zBlEfEhcOpc2huAl6rnLwEbW+3UFEXEgYj4rHr+B50DfAmZxhUdR6vF2dUjgDXAG1V7NvH8Q9JS4BbguWpZZB5TRpy/+lRp+QvKzGGl5a+2B1BLgB8mLf9YtZXggog4UD3/Gbigl52ZCknLgWuAj8g4rupS8U7gIPAe8A1wJCLGq1VyPP6eAh4EJqrlReQfUy6cvzJQSv6CInNYUfnLN5HPgOiUNmZZ3ihpHvAmcH9E/D75d7nFFREnI2IVsJTO1YMretylKZF0K3AwIj7tdV+sXLmd55OVlL+grBxWYv4aaHl7PwHLJi0vrdpK8IukiyLigKSL6PzHkBVJs+kkn5cj4q2qOfu4IuKIpG3A9cACSQPVfzy5HX83ALdLWg8MA+cCT5N3TDlx/upjpeYvKCaHFZe/2r4C9TFweXXX/SBwJ/BOy32YKe8Am6rnm4C3e9iXxqrPop8H9kbEE5N+lWVckhZLWlA9nwPcTOe+iG3AHdVq2cQDEBEPR8TSiFhO59z5ICLuJuOYMuP81adKy19QXg4rMn9FRKsPYD3wFZ3Pch9pe/vTFMMrwAHgBJ3PbO+h81nuVuBr4H1gpNf9bBjTjXQub+8CdlaP9bnGBVwF7Kji2Q08WrWvALYD+4DXgaFe9/UM47sJ2FJSTDk8nL/681Fa/qpiKjaHlZK//E3kZmZmZg35JnIzMzOzhjyAMjMzM2vIAygzMzOzhjyAMjMzM2vIAygzMzOzhjyAMjMzM2vIAygzMzOzhjyAMjMzM2vob/beiv8WSY8qAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "EwIkYvQy3vOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER_NAME='/content/drive/MyDrive/FYP/outputs/'\n",
        "np.save(OUTPUT_FOLDER_NAME + 'train_labels_one_hot.npy', train_labels_one_hot)\n",
        "np.save(OUTPUT_FOLDER_NAME + 'train_labels.npy', y)\n",
        "np.save(OUTPUT_FOLDER_NAME + 'val_labels_one_hot.npy', val_labels_one_hot)\n",
        "np.save(OUTPUT_FOLDER_NAME + 'val_labels.npy', y_val)\n",
        "\n",
        "np.save(OUTPUT_FOLDER_NAME + 'train_hog_slide_images.npy', np.array(hog_slide_images))\n",
        "np.save(OUTPUT_FOLDER_NAME + 'train_hog_slide_features.npy', np.array(hog_slide_features))\n",
        "np.save(OUTPUT_FOLDER_NAME + 'val_hog_slide_images.npy', np.array(val_hog_slide_images))\n",
        "np.save(OUTPUT_FOLDER_NAME + 'val_hog_slide_features.npy', np.array(val_hog_slide_features))\n",
        "\n",
        "np.save(OUTPUT_FOLDER_NAME + 'train_images.npy', X)\n",
        "np.save(OUTPUT_FOLDER_NAME + 'val_images.npy', X_val)"
      ],
      "metadata": {
        "id": "3amlDZGMnA9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_hog_slid_img = np.load(OUTPUT_FOLDER_NAME + \"train_hog_slide_images.npy\").reshape(-1, 48, 48, 1)\n",
        "X_imgs = np.load(OUTPUT_FOLDER_NAME + \"train_images.npy\")\n",
        "X_new = np.concatenate((X_imgs,X_hog_slid_img),axis = 1)"
      ],
      "metadata": {
        "id": "9eGnpnAKorR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_hog_slid_img_val = np.load(OUTPUT_FOLDER_NAME + \"val_hog_slide_images.npy\").reshape(-1, 48, 48, 1)\n",
        "X_imgs_val = np.load(OUTPUT_FOLDER_NAME + \"val_images.npy\")\n",
        "X_new_val = np.concatenate((X_imgs_val,X_hog_slid_img_val),axis = 1)"
      ],
      "metadata": {
        "id": "WjpgieLCbgUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(OUTPUT_FOLDER_NAME + 'train_image_features.npy', X_new)\n",
        "np.save(OUTPUT_FOLDER_NAME + 'val_image_features.npy', X_new_val)"
      ],
      "metadata": {
        "id": "dEIrZeAT3XDo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "improved-face-detection-grey.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hjjBvMYEvjN9",
        "ydhF5ayLvwiQ",
        "mcJ3EvDqwLdR",
        "n6FMlNwD3nl8"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}